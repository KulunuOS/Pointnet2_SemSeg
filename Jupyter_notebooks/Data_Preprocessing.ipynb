{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Dataset\n",
    "\n",
    "- This notebook assumes that you already have a dataset generated in BOP Format in /dataset directory.\n",
    "- Once the preprocessing is completed you can use the custom dataloader in the /lib directory for training etc\n",
    "- Here we generate Keypoints, Corners and Pointcloud Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "import pickle as pkl\n",
    "import json\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "root_path = \"/media/kulunu/Elements SE/Datasets/Nema17_reducer_dataset\"\n",
    "data_path = root_path + \"/stage_1\"\n",
    "\n",
    "seg_format = '.npy'\n",
    "img_id_leading_zeros = 0\n",
    "dpt_format = \".png\"\n",
    "rgb_format = \".png\"\n",
    "\n",
    "# data were rendered like this\n",
    "# python3 render_icp_data.py -m Nema17 sun_gear housing carrier cover -d Nema17_reducer -s 1\n",
    "# so object ids :\n",
    "# Nema17=1 sun_gear=2 housing=3 carrier=4 cover=5\n",
    "\n",
    "# For this notebook the names of mesh files were changed to numbers eg: obj_000001.ply\n",
    "# codebase at /captaib_backup/datagen_ws\n",
    "\n",
    "\n",
    "class Adapt_Dataset():\n",
    "\n",
    "    def __init__(self, scene_id):\n",
    "        \n",
    "        #self.dataset_name = dataset_name\n",
    "        self.root_dir = root_path\n",
    "        self.dat_dir = root_path + \"/\" + scene_id\n",
    "        self.dir = self.dat_dir \n",
    "        self.rgb_dir = self.dir +'/rgb'  \n",
    "        self.dpt_dir = self.dir+'/depth'\n",
    "        self.msk_dir = self.dir+'/mask'\n",
    "        self.segmap_dir = self.dir+'/seg_maps'\n",
    "        self.kps_dir = self.root_dir+'/keypoints'\n",
    "        self.model_dir = self.root_dir+'/model_meshes'\n",
    "        self.pcd_dir = self.root_dir+'/model_pointcloud'\n",
    "        self.n_keypoints = 8\n",
    "        self.n_objects = 5\n",
    "        self.n_sample_points = 8192 + 4096   # 12288\n",
    "\n",
    "        self.mesh_dict = { }\n",
    "        self.corners_dict = { }\n",
    "        self.kps_dict = { }\n",
    "        self.rgb = None\n",
    "\n",
    "        self.corners_file = os.path.join(self.kps_dir,'corners.pkl')\n",
    "        \n",
    "        if self.n_keypoints == 8:\n",
    "            kp_type = 'farthest_8'\n",
    "        else:\n",
    "            kp_type = 'farthest_{}'.format(self.n_keypoints)\n",
    "            \n",
    "    \n",
    "    def get_cam_info(self,idx):\n",
    "                 scene_cam_path = os.path.join(self.dir,'scene_camera.json')\n",
    "\n",
    "                 if os.path.exists(scene_cam_path): \n",
    "                    with open(scene_cam_path,\"r\") as k:\n",
    "                        for i,j in enumerate(k):\n",
    "                            im_dict = json.loads(j)\n",
    "                            if i == idx:\n",
    "                                this_cam = im_dict\n",
    "                                \n",
    "                        cam_K = this_cam[str(idx)]['cam_K']\n",
    "                        dpt_cam_K = this_cam[str(idx)]['dpt_cam_K']\n",
    "                        K = np.array(cam_K).reshape(3,3)\n",
    "                        dpt_K = np.array(dpt_cam_K).reshape(3,3)\n",
    "                        cam_scale =  this_cam[str(idx)]['depth_scale']\n",
    "\n",
    "                    return K,dpt_K, cam_scale\n",
    "\n",
    "                 else:\n",
    "                      print(\"missing scene_camera.json :\")\n",
    "                    \n",
    "    def get_segmap(self,idx):\n",
    "        segmap = np.load(os.path.join(self.segmap_dir,str(idx).zfill(img_id_leading_zeros)+'_seg_map'+seg_format))\n",
    "        segmap_flattened = segmap.flatten()\n",
    "        \n",
    "        return  segmap_flattened\n",
    "        \n",
    "    def get_item(self, idx):\n",
    "        with open(os.path.join(self.dir, 'cld_rgb_nrms/{}.pkl'.format(idx)),'rb') as f:\n",
    "                cld_rgb_nrms = pkl.load(f)\n",
    "                \n",
    "        labels = np.load(os.path.join(self.dir, 'labels/{}.npy'.format(idx)))\n",
    "        cld_rgb_nrms = np.asarray(cld_rgb_nrms)\n",
    "        \n",
    "        return torch.LongTensor(labels.astype(np.int32)), torch.from_numpy(cld_rgb_nrms.astype(np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.rgb_dir))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.get_item(idx)\n",
    "        return data\n",
    "    \n",
    "    def get_image(self,idx):\n",
    "        with Image.open(os.path.join(self.rgb_dir,str(idx).zfill(img_id_leading_zeros)+ rgb_format)) as ri:\n",
    "                rgb = np.array(ri)[:, :, :3]\n",
    "                rgb = np.transpose(rgb, (2, 0, 1))\n",
    "        \n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kps_corners_pcds():\n",
    "    dataset = Adapt_Dataset(scene_id='stage_1')\n",
    "    cls_ids = [i for i in range(1,5)]\n",
    "    corners = []\n",
    "    \n",
    "    \n",
    "    for cls_id in cls_ids:\n",
    "        if not os.path.exists(dataset.kps_dir):\n",
    "            os.makedirs(dataset.kps_dir)\n",
    "\n",
    "        kps_path = os.path.join(dataset.kps_dir,str(cls_id)+\"_fps_{}.\".format(dataset.n_keypoints))\n",
    "        corners_path = os.path.join(dataset.kps_dir,'corners.pkl')\n",
    "        mesh = o3d.io.read_triangle_mesh(dataset.model_dir +'/obj_'+str(cls_id).zfill(6)+'.ply')\n",
    "        pcd = mesh.sample_points_poisson_disk(number_of_points=30000)\n",
    "        \n",
    "\n",
    "        if not os.path.exists(dataset.pcd_dir):\n",
    "            os.makedirs(dataset.pcd_dir)\n",
    "\n",
    "        o3d.io.write_point_cloud(dataset.pcd_dir+'/obj_'+str(cls_id).zfill(6)+'.ply', pcd)\n",
    "\n",
    "        if not os.path.exists(kps_path):\n",
    "            print('Writing kps for class '+str(cls_id))\n",
    "            \n",
    "            pts = np.asarray(pcd.points)\n",
    "            tensor_pcd = o3d.t.geometry.PointCloud(pts)\n",
    "            fps_pcd = tensor_pcd.farthest_point_down_sample(dataset.n_keypoints)\n",
    "            print(\"done\")\n",
    "            fps_pcd = fps_pcd.to_legacy()\n",
    "            o3d.io.write_point_cloud(os.path.join(kps_path+'pcd'), fps_pcd)\n",
    "\n",
    "            with open(os.path.join(kps_path+'pkl'), 'wb') as file:\n",
    "                pkl.dump(np.asarray(fps_pcd.points), file)\n",
    "\n",
    "\n",
    "        # calculate corners\n",
    "        if not os.path.exists(corners_path):\n",
    "            print('Writing corners')\n",
    "            ctrs = copy.deepcopy(pcd).get_minimal_oriented_bounding_box()\n",
    "            ctrs = np.asarray(ctrs.get_box_points())\n",
    "            corners.append(ctrs)\n",
    "\n",
    "    if not os.path.exists(corners_path):\n",
    "        with open(corners_path, 'wb') as file:\n",
    "            pkl.dump(corners, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pcl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cld , choose\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Lets do cld_rgb_nrms itself instead of cld_choose_nrms!\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpcl\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Basic_Utils\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pcl'"
     ]
    }
   ],
   "source": [
    "# this part runs on pvn3d\n",
    "\n",
    "#Function to project depth to pointcloud\n",
    "def dpt_2_cld( depth_frame, K,segMask = None,cam_scale=1):\n",
    "\n",
    "    w = depth_frame.shape[1]\n",
    "    h = depth_frame.shape[0]\n",
    "    \n",
    "    xmap = np.array([[j for i in range(w)] for j in range(h)])\n",
    "    ymap = np.array([[i for i in range(w)] for j in range(h)])\n",
    "    \n",
    "    dpt = np.array(depth_frame, dtype=np.float32)\n",
    "    dpt = dpt/1000\n",
    "    \n",
    "    if len(dpt.shape) > 2:\n",
    "            dpt = dpt[:, :, 0]\n",
    "    msk_dp = dpt > -1\n",
    "    choose = msk_dp.flatten().nonzero()[0].astype(np.uint32)\n",
    "\n",
    "    if len(choose) < 1:\n",
    "        return None, None\n",
    "        \n",
    "    dpt_mskd = dpt.flatten()[choose][:, np.newaxis].astype(np.float32)\n",
    "    xmap_mskd = xmap.flatten()[choose][:, np.newaxis].astype(np.float32)\n",
    "    ymap_mskd = ymap.flatten()[choose][:, np.newaxis].astype(np.float32)\n",
    "    cam_cx, cam_cy = K[0][2], K[1][2]\n",
    "    cam_fx, cam_fy = K[0][0], K[1][1]\n",
    "    \n",
    "    if segMask is not None:\n",
    "             \n",
    "        focus_points = np.argwhere(segMask != 0)\n",
    "        focus = segMask != 0\n",
    "        \n",
    "        # projecting only the focus\n",
    "        pt2 = dpt_mskd[focus.flatten()] / cam_scale\n",
    "        pt0b= (ymap_mskd[focus.flatten()] - cam_cx) * pt2 / cam_fx\n",
    "        pt1b= (xmap_mskd[focus.flatten()] - cam_cy) * pt2 / cam_fy\n",
    "        focus_points = np.concatenate((pt0b, pt1b, pt2),axis=1)\n",
    "               \n",
    "        return focus_points , choose\n",
    "    \n",
    "    else :\n",
    "\n",
    "        # projecting the cloud as a whole    \n",
    "        pt2 = dpt_mskd / cam_scale\n",
    "        pt0 = (ymap_mskd - cam_cx) * pt2 / cam_fx\n",
    "        pt1 = (xmap_mskd - cam_cy) * pt2 / cam_fy\n",
    "        cld = np.concatenate((pt0, pt1, pt2),axis=1)\n",
    "        \n",
    "        return cld , choose\n",
    "\n",
    "    \n",
    "# Lets do cld_rgb_nrms itself instead of cld_choose_nrms!\n",
    "\n",
    "import pcl\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from lib.utils.basic_utils import Basic_Utils\n",
    "from common import Config\n",
    "config = Config(dataset_name='Adapt')\n",
    "bs_utils = Basic_Utils(config)\n",
    "\n",
    "dataset = Adapt_Dataset(scene_id='stage_2')\n",
    "cld_rgb_nrms_path = os.path.join(dataset.dat_dir, 'cld_rgb_nrms')\n",
    "\n",
    "\n",
    "def get_normal( cld):\n",
    "        cloud = pcl.PointCloud()\n",
    "        cld = cld.astype(np.float32)\n",
    "        cloud.from_array(cld)\n",
    "        ne = cloud.make_NormalEstimation()\n",
    "        kdtree = cloud.make_kdtree()\n",
    "        ne.set_SearchMethod(kdtree)\n",
    "        ne.set_KSearch(50)\n",
    "        n = ne.compute()\n",
    "        n = n.to_array()\n",
    "        return n\n",
    "\n",
    "rgb_directory = os.path.join(dataset.dir,'rgb')\n",
    "for filename in os.listdir(rgb_directory):\n",
    "    #print(\"filename\",filename)\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    #print(\"name\", name)\n",
    "    idx = name.lstrip('0')\n",
    "    idx = int(idx) if idx else 0\n",
    "\n",
    "    K,dpt_K, cam_scale = dataset.get_cam_info(idx)\n",
    "    segmap_flattened = dataset.get_segmap(idx)\n",
    "\n",
    "    with Image.open(os.path.join(dataset.dpt_dir,str(idx).zfill(img_id_leading_zeros)+ dpt_format)) as di:\n",
    "        dpt = np.array(di)\n",
    "        \n",
    "    with Image.open(os.path.join(dataset.rgb_dir,str(idx).zfill(img_id_leading_zeros)+ rgb_format)) as ri:\n",
    "                rgb = np.array(ri)[:, :, :3]\n",
    "                rgb = np.transpose(rgb, (2, 0, 1))\n",
    "\n",
    "\n",
    "    #Back-projection util function\n",
    "    cld, choose = dpt_2_cld(dpt, dpt_K)\n",
    "    #choose = choose.reshape(choose.shape[0],1)\n",
    "    #print(\"choose :\", np.shape(choose))\n",
    "    \n",
    "    segmap_flattened = segmap_flattened[choose]\n",
    "\n",
    "    # sample only 12288 points and get the respective cld_rgb_nrm + labels\n",
    "    rgb_lst = []\n",
    "    for ic in range(rgb.shape[0]):\n",
    "        rgb_lst.append(\n",
    "            rgb[ic].flatten()[choose].astype(np.float32)\n",
    "        )\n",
    "     \n",
    "    rgb_pt = np.transpose(np.array(rgb_lst), (1, 0)).copy()\n",
    "    #print(\"rgb :\",np.shape(rgb_pt))\n",
    "    \n",
    "    choose = np.array([choose], dtype= np.uint32)\n",
    "    choose_2 = np.array([i for i in range(len(choose[0, :]))])\n",
    "    \n",
    "    \n",
    "    if len(choose_2) < 400:\n",
    "        print(\"not_enough points\")\n",
    "        \n",
    "    if len(choose_2) > config.n_sample_points:\n",
    "        c_mask = np.zeros(len(choose_2), dtype=int)\n",
    "        c_mask[:config.n_sample_points] = 1\n",
    "        np.random.shuffle(c_mask)\n",
    "        choose_2 = choose_2[c_mask.nonzero()]\n",
    "    else:\n",
    "        choose_2 = np.pad(choose_2, (0, dataset.n_sample_points-len(choose_2)), 'wrap')\n",
    "    \n",
    "    #print(\"choose_2 :\", np.shape(choose_2))\n",
    "    \n",
    "    \n",
    "    rgb_pt = rgb_pt[choose_2,:]\n",
    "    #print(\"rgb :\", np.shape(rgb_pt))\n",
    "    \n",
    "    cld = cld[choose_2, :]\n",
    "    #print(\"cld :\", np.shape(cld))\n",
    "    normals = get_normal(cld)[:,:3]\n",
    "    normals[np.isnan(normals)] = 0.\n",
    "    #print(\"normals :\",np.shape(normals))\n",
    "    \n",
    "    cld_rgb_nrm = np.concatenate((cld, rgb_pt, normals), axis=1)\n",
    "    \n",
    "    \n",
    "    #cld_rgb_nrm = cld_rgb_nrm[choose_2, :]\n",
    "    \n",
    "    # labels are the corresponding per sampled point, segmap is the perpoint labels for all points\n",
    "    labels = segmap_flattened[choose_2].astype(np.int32)\n",
    "    \n",
    "    #save the choose with each label \n",
    "    choose = choose[:, choose_2]\n",
    "    arr = [[labels],[choose]]\n",
    "    #print(\"arr\", arr)\n",
    "    \n",
    "    \n",
    "    label_path = os.path.join(dataset.dat_dir, 'labels')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.makedirs(label_path)\n",
    "    if not os.path.exists(os.path.join(label_path,str(idx)+'.npy')):\n",
    "        np.save(os.path.join(label_path,str(idx)+'.npy'), labels)  # NOTE! Only label is saved. you can save arr next time!\n",
    "    #all_arr = np.concatenate( (cld, choose.reshape(choose.shape[0],1), normals[:,:3]) , axis = 1)\n",
    "    \n",
    "    if not os.path.exists(cld_rgb_nrms_path):\n",
    "        os.makedirs(cld_rgb_nrms_path)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(cld_rgb_nrms_path,str(idx)+'.pkl')):\n",
    "        print('Writing file '+str(idx)) \n",
    "        with open(os.path.join(cld_rgb_nrms_path,str(idx)+'.pkl'), 'wb') as file:\n",
    "            pkl.dump(cld_rgb_nrm,file)\n",
    "\n",
    "            \n",
    "            \n",
    "# segmap and cld_rgb_nrms have to be downsampled!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_0.17",
   "language": "python",
   "name": "open3d_0.17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
