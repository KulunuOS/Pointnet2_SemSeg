{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d173c34",
   "metadata": {},
   "source": [
    "## Sampling Pointcloud and extracting features for the sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 100em; }</style>\"))\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pcl\n",
    "from PIL import Image\n",
    "\n",
    "from lib.custom_dataloader import Dataset\n",
    "from lib.seg_utils import dpt_2_cld,draw_p2ds,project_p3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_path = \"/media/kulunu/Elements SE/Datasets/Nema17_reducer_dataset\"\n",
    "\n",
    "seg_format = '.npy'\n",
    "img_id_leading_zeros = 0\n",
    "dpt_format = \".png\"\n",
    "rgb_format = \".png\"\n",
    "\n",
    "dataset = Dataset(root_path, scene_id ='stage_5')\n",
    "cld_rgb_nrms_path = os.path.join(dataset.dir, 'cld_rgb_nrms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6a965",
   "metadata": {},
   "source": [
    "### Sample and Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part runs on pvn3d\n",
    "# TODO:Only run the calculations if the folders are empty\n",
    "\n",
    "def get_normal( cld):\n",
    "        cloud = pcl.PointCloud()\n",
    "        cld = cld.astype(np.float32)\n",
    "        cloud.from_array(cld)\n",
    "        ne = cloud.make_NormalEstimation()\n",
    "        kdtree = cloud.make_kdtree()\n",
    "        ne.set_SearchMethod(kdtree)\n",
    "        ne.set_KSearch(50)\n",
    "        n = ne.compute()\n",
    "        n = n.to_array()\n",
    "        return n\n",
    "\n",
    "rgb_directory = os.path.join(dataset.dir,'rgb')\n",
    "for filename in os.listdir(rgb_directory):\n",
    "    name, extension = os.path.splitext(filename)\n",
    "\n",
    "    idx = name.lstrip('0')\n",
    "    idx = int(idx) if idx else 0\n",
    "\n",
    "    K,dpt_K, cam_scale = dataset.get_cam_info(idx)\n",
    "    \n",
    "    segmap = np.load(os.path.join(dataset.segmap_dir,str(idx).zfill(img_id_leading_zeros)+'_seg_map'+seg_format))\n",
    "    segmap_flattened = segmap.flatten()\n",
    "    \n",
    "    with Image.open(os.path.join(dataset.dpt_dir,str(idx).zfill(img_id_leading_zeros)+ dpt_format)) as di:\n",
    "        dpt = np.array(di)\n",
    "        \n",
    "    with Image.open(os.path.join(dataset.rgb_dir,str(idx).zfill(img_id_leading_zeros)+ rgb_format)) as ri:\n",
    "                rgb = np.array(ri)[:, :, :3]\n",
    "                rgb = np.transpose(rgb, (2, 0, 1))\n",
    "\n",
    "\n",
    "    #Back-projection util function\n",
    "    cld, choose = dpt_2_cld(dpt, dpt_K)\n",
    " \n",
    "    # load precalculated segmaps or labels   \n",
    "    segmap_flattened = segmap_flattened[choose]\n",
    "\n",
    "    # sample only 12288 points and get the respective cld_rgb_nrm + labels\n",
    "    rgb_lst = []\n",
    "    for ic in range(rgb.shape[0]):\n",
    "        rgb_lst.append(\n",
    "            rgb[ic].flatten()[choose].astype(np.float32)\n",
    "        )\n",
    "     \n",
    "    rgb_pt = np.transpose(np.array(rgb_lst), (1, 0)).copy()\n",
    "    \n",
    "    \n",
    "    choose = np.array([choose], dtype= np.uint32)\n",
    "    choose_2 = np.array([i for i in range(len(choose[0, :]))])\n",
    "    \n",
    "    \n",
    "    if len(choose_2) < 400:\n",
    "        print(\"not_enough points\")\n",
    "        \n",
    "    if len(choose_2) > dataset.n_sample_points:\n",
    "        c_mask = np.zeros(len(choose_2), dtype=int)\n",
    "        c_mask[:dataset.n_sample_points] = 1\n",
    "        np.random.shuffle(c_mask)\n",
    "        choose_2 = choose_2[c_mask.nonzero()]\n",
    "    else:\n",
    "        choose_2 = np.pad(choose_2, (0, dataset.n_sample_points-len(choose_2)), 'wrap')\n",
    "    \n",
    "    # select only the sampled indexes    \n",
    "    rgb_pt = rgb_pt[choose_2,:]  \n",
    "    cld = cld[choose_2, :]\n",
    "\n",
    "    normals = get_normal(cld)[:,:3]\n",
    "    normals[np.isnan(normals)] = 0.\n",
    "\n",
    "    cld_rgb_nrm = np.concatenate((cld, rgb_pt, normals), axis=1)\n",
    "    \n",
    "    # labels are the corresponding per sampled point, segmap is the perpoint labels for all points\n",
    "    labels = segmap_flattened[choose_2].astype(np.int32)\n",
    "    \n",
    "    #save the choose with each label \n",
    "    choose = np.squeeze(choose[:, choose_2])\n",
    "    arr = [labels,choose]\n",
    "\n",
    "    label_path = os.path.join(dataset.dir, 'labels')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.makedirs(label_path)\n",
    "    if not os.path.exists(os.path.join(label_path,str(idx)+'.npy')):\n",
    "        np.save(os.path.join(label_path,str(idx)+'.npy'), arr)  # NOTE! Only label is saved. you can save arr next time!\n",
    "    #all_arr = np.concatenate( (cld, choose.reshape(choose.shape[0],1), normals[:,:3]) , axis = 1)\n",
    "    \n",
    "    if not os.path.exists(cld_rgb_nrms_path):\n",
    "        os.makedirs(cld_rgb_nrms_path)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(cld_rgb_nrms_path,str(idx)+'.pkl')):\n",
    "        print('Writing file '+str(idx)) \n",
    "        with open(os.path.join(cld_rgb_nrms_path,str(idx)+'.pkl'), 'wb') as file:\n",
    "            pkl.dump(cld_rgb_nrm,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb137b",
   "metadata": {},
   "source": [
    "### Always visualize data to confrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Visualize random data, 4 tiles\n",
    "idx = 7\n",
    "data_torch = dataset.get_item(idx=idx)\n",
    "\n",
    "cu_dt = [item.contiguous().to(\"cuda\", non_blocking=True) for item in data_torch]    \n",
    "labels, cld_rgb_nrm, choose, rgb  = cu_dt\n",
    "\n",
    "pcld = cld_rgb_nrm.squeeze().cpu().numpy()[:,0:3]\n",
    "labels = labels.squeeze().cpu().numpy()\n",
    "rgb = rgb.cpu().numpy().transpose(1, 2, 0)[...,::-1].copy()\n",
    "\n",
    "K,dpt_K, cam_scale = dataset.get_cam_info(idx=idx)\n",
    "\n",
    "color = (255,0,0)\n",
    "p2ds = project_p3d(pcld[labels == 1], cam_scale, K)\n",
    "rgb = draw_p2ds(rgb, p2ds,color,3)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(np.asarray(rgb,np.int32),interpolation='none')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Create a visualization gif\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvn3d",
   "language": "python",
   "name": "pvn3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
